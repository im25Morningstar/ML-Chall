{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "240e16fafcde42c8a66b763c14db1f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10684be9ef8e4f9cb1dc41c93e0ca371",
              "IPY_MODEL_e50ec5abce2548a0a5d4c82042fd817d",
              "IPY_MODEL_f33b2a270ba44017bdf8f0885b91d098"
            ],
            "layout": "IPY_MODEL_5a09e365ded24676bba0f505ecee0980"
          }
        },
        "10684be9ef8e4f9cb1dc41c93e0ca371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5baf57b9abb44046ac5d1db9abdafe7e",
            "placeholder": "​",
            "style": "IPY_MODEL_6e0392ed764d48df88d26c2b899d8c70",
            "value": "Loading weights: 100%"
          }
        },
        "e50ec5abce2548a0a5d4c82042fd817d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15b6082ba58b4811929b10e24510ddbd",
            "max": 202,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0103a57862342eebb39912b0f7d8ccf",
            "value": 202
          }
        },
        "f33b2a270ba44017bdf8f0885b91d098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a90c3db1c15a4f2c9f7f7ce0a95c046e",
            "placeholder": "​",
            "style": "IPY_MODEL_1c96eaaa871a4a7d8f9d6af6c2aa5c99",
            "value": " 202/202 [00:00&lt;00:00, 329.07it/s, Materializing param=cls.predictions.transform.dense.weight]"
          }
        },
        "5a09e365ded24676bba0f505ecee0980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5baf57b9abb44046ac5d1db9abdafe7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e0392ed764d48df88d26c2b899d8c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15b6082ba58b4811929b10e24510ddbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0103a57862342eebb39912b0f7d8ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a90c3db1c15a4f2c9f7f7ce0a95c046e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c96eaaa871a4a7d8f9d6af6c2aa5c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wJeOU5coI0dZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizerFast, BertForMaskedLM, DataCollatorForLanguageModeling\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "train_df[\"catalog_content\"] = train_df[\"catalog_content\"].fillna(\"\").str.strip()\n",
        "test_df[\"catalog_content\"] = test_df[\"catalog_content\"].fillna(\"\").str.strip()\n",
        "\n",
        "print(train_df.head())\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gw6aV0pNJK8X",
        "outputId": "3899447f-c8c2-421a-9f24-64bc855b4b68"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sample_id                                    catalog_content  \\\n",
            "0      33127  Item Name: La Victoria Green Taco Sauce Mild, ...   \n",
            "1     198967  Item Name: Salerno Cookies, The Original Butte...   \n",
            "2     261251  Item Name: Bear Creek Hearty Soup Bowl, Creamy...   \n",
            "3      55858  Item Name: Judee’s Blue Cheese Powder 11.25 oz...   \n",
            "4     292686  Item Name: kedem Sherry Cooking Wine, 12.7 Oun...   \n",
            "\n",
            "                                          image_link  price  \n",
            "0  https://m.media-amazon.com/images/I/51mo8htwTH...   4.89  \n",
            "1  https://m.media-amazon.com/images/I/71YtriIHAA...  13.12  \n",
            "2  https://m.media-amazon.com/images/I/51+PFEe-w-...   1.97  \n",
            "3  https://m.media-amazon.com/images/I/41mu0HAToD...  30.34  \n",
            "4  https://m.media-amazon.com/images/I/41sA037+Qv...  66.49  \n",
            "   sample_id                                    catalog_content  \\\n",
            "0     100179  Item Name: Rani 14-Spice Eshamaya's Mango Chut...   \n",
            "1     245611  Item Name: Natural MILK TEA Flavoring extract ...   \n",
            "2     146263  Item Name: Honey Filled Hard Candy - Bulk Pack...   \n",
            "3      95658  Item Name: Vlasic Snack'mm's Kosher Dill 16 Oz...   \n",
            "4      36806  Item Name: McCormick Culinary Vanilla Extract,...   \n",
            "\n",
            "                                          image_link  \n",
            "0  https://m.media-amazon.com/images/I/71hoAn78AW...  \n",
            "1  https://m.media-amazon.com/images/I/61ex8NHCIj...  \n",
            "2  https://m.media-amazon.com/images/I/61KCM61J8e...  \n",
            "3  https://m.media-amazon.com/images/I/51Ex6uOH7y...  \n",
            "4  https://m.media-amazon.com/images/I/71QYlrOMoS...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smape(y_true, y_pred):\n",
        "    numerator = np.abs(y_true - y_pred)\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
        "    return np.mean(numerator / np.clip(denominator, 1e-8, None))\n"
      ],
      "metadata": {
        "id": "DfFRfR4qKlbK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LoraMLMTrainer:\n",
        "    def __init__(self, model_name=\"bert-base-uncased\", lora_r=16, lora_alpha=32, lora_dropout=0.05):\n",
        "        self.tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "        self.model = BertForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "        # Correct PEFT configuration for BERT MLM\n",
        "        peft_config = LoraConfig(\n",
        "            r=lora_r,\n",
        "            lora_alpha=lora_alpha,\n",
        "            lora_dropout=lora_dropout,\n",
        "            target_modules=[\"query\", \"value\"],\n",
        "            bias=\"none\",\n",
        "            task_type=\"CAUSAL_LM\"   # correct for MLM models in PEFT\n",
        "        )\n",
        "\n",
        "        # Attach LoRA adapters\n",
        "        self.model = get_peft_model(self.model, peft_config)\n",
        "\n",
        "    def tokenize_function(self, examples):\n",
        "        return self.tokenizer(\n",
        "            examples[\"text\"],\n",
        "            truncation=True,\n",
        "            max_length=128\n",
        "        )\n",
        "\n",
        "    def train(self, texts, output_dir=\"lora_mlm_model\"):\n",
        "        # Prepare dataset\n",
        "        df = pd.DataFrame({\"text\": texts})\n",
        "        tokenized = self.tokenize_function(df.to_dict(\"list\"))\n",
        "\n",
        "        class SimpleDS(Dataset):\n",
        "            def __init__(self, encodings):\n",
        "                self.encodings = encodings\n",
        "            def __len__(self):\n",
        "                return len(self.encodings[\"input_ids\"])\n",
        "            def __getitem__(self, idx):\n",
        "                return {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "\n",
        "        train_dataset = SimpleDS(tokenized)\n",
        "\n",
        "        # MLM masking\n",
        "        data_collator = DataCollatorForLanguageModeling(\n",
        "            tokenizer=self.tokenizer,\n",
        "            mlm=True,\n",
        "            mlm_probability=0.15\n",
        "        )\n",
        "\n",
        "        # TrainingArguments\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=output_dir,\n",
        "            per_device_train_batch_size=16,\n",
        "            gradient_accumulation_steps=2,\n",
        "            num_train_epochs=1,\n",
        "            logging_steps=100,\n",
        "            save_steps=5000,\n",
        "            remove_unused_columns=False,\n",
        "            fp16=True,\n",
        "            report_to=\"none\"\n",
        "        )\n",
        "\n",
        "        # Trainer (no tokenizer argument)\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            data_collator=data_collator\n",
        "        )\n",
        "\n",
        "        # Train LoRA-MLM model\n",
        "        trainer.train()\n",
        "\n",
        "        # Save model + tokenizer\n",
        "        self.model.save_pretrained(output_dir)\n",
        "        self.tokenizer.save_pretrained(output_dir)\n"
      ],
      "metadata": {
        "id": "vbHHH3rmKmc_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = train_df[\"catalog_content\"].tolist()\n",
        "\n",
        "mlm_trainer = LoraMLMTrainer()\n",
        "mlm_trainer.train(texts, output_dir=\"lora_mlm_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335,
          "referenced_widgets": [
            "240e16fafcde42c8a66b763c14db1f94",
            "10684be9ef8e4f9cb1dc41c93e0ca371",
            "e50ec5abce2548a0a5d4c82042fd817d",
            "f33b2a270ba44017bdf8f0885b91d098",
            "5a09e365ded24676bba0f505ecee0980",
            "5baf57b9abb44046ac5d1db9abdafe7e",
            "6e0392ed764d48df88d26c2b899d8c70",
            "15b6082ba58b4811929b10e24510ddbd",
            "e0103a57862342eebb39912b0f7d8ccf",
            "a90c3db1c15a4f2c9f7f7ce0a95c046e",
            "1c96eaaa871a4a7d8f9d6af6c2aa5c99"
          ]
        },
        "id": "Be9jsHeiKwQ7",
        "outputId": "6151a83f-b6e1-4a48-82c3-b99d109a2f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/202 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "240e16fafcde42c8a66b763c14db1f94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForMaskedLM LOAD REPORT from: bert-base-uncased\n",
            "Key                         | Status     |  | \n",
            "----------------------------+------------+--+-\n",
            "bert.pooler.dense.weight    | UNEXPECTED |  | \n",
            "cls.seq_relationship.bias   | UNEXPECTED |  | \n",
            "cls.seq_relationship.weight | UNEXPECTED |  | \n",
            "bert.pooler.dense.bias      | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17' max='2344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  17/2344 08:41 < 22:28:38, 0.03 it/s, Epoch 0.01/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEmbedder:\n",
        "    def __init__(self, model_path=\"lora_mlm_model\"):\n",
        "        self.tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
        "        self.model = BertForMaskedLM.from_pretrained(model_path)\n",
        "        self.model.eval()\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def embed_batch(self, texts):\n",
        "        tokens = self.tokenizer(\n",
        "            texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.bert(**tokens)\n",
        "            hidden = outputs.last_hidden_state\n",
        "            embeddings = hidden.mean(dim=1)\n",
        "\n",
        "        return embeddings.cpu().numpy()\n",
        "\n",
        "    def generate_embeddings(self, df, batch_size=64):\n",
        "        all_embeddings = []\n",
        "        for i in range(0, len(df), batch_size):\n",
        "            batch_text = df[\"catalog_content\"].iloc[i:i+batch_size].tolist()\n",
        "            batch_embeds = self.embed_batch(batch_text)\n",
        "            all_embeddings.append(batch_embeds)\n",
        "\n",
        "        return np.vstack(all_embeddings)\n"
      ],
      "metadata": {
        "id": "23GABFjRK0gZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = TextEmbedder(\"lora_mlm_model\")\n",
        "\n",
        "train_embeddings = embedder.generate_embeddings(train_df)\n",
        "test_embeddings = embedder.generate_embeddings(test_df)\n",
        "\n",
        "np.save(\"train_embeds.npy\", train_embeddings)\n",
        "np.save(\"test_embeds.npy\", test_embeddings)\n"
      ],
      "metadata": {
        "id": "gTP0Kcr0MVDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnsembleRegressor:\n",
        "    def __init__(self):\n",
        "        self.xgb_model = None\n",
        "        self.lgbm_model = None\n",
        "\n",
        "    def train_xgb(self, X_train, y_train):\n",
        "        model = xgb.XGBRegressor(\n",
        "            n_estimators=500,\n",
        "            learning_rate=0.03,\n",
        "            max_depth=8,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            objective=\"reg:squarederror\",\n",
        "            tree_method=\"gpu_hist\" if torch.cuda.is_available() else \"hist\",\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "        self.xgb_model = model\n",
        "\n",
        "    def train_lgbm(self, X_train, y_train):\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"learning_rate\": 0.03,\n",
        "            \"num_leaves\": 64,\n",
        "            \"feature_fraction\": 0.8,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5\n",
        "        }\n",
        "        dataset = lgb.Dataset(X_train, y_train)\n",
        "        self.lgbm_model = lgb.train(params, dataset, num_boost_round=500)\n",
        "\n",
        "    def predict(self, X, w1=0.5, w2=0.5):\n",
        "        p1 = self.xgb_model.predict(X)\n",
        "        p2 = self.lgbm_model.predict(X)\n",
        "        return w1 * p1 + w2 * p2\n"
      ],
      "metadata": {
        "id": "lt55kfAiMWI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_embeddings\n",
        "y = train_df[\"price\"].values\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "ensemble = EnsembleRegressor()\n",
        "ensemble.train_xgb(X_train, y_train)\n",
        "ensemble.train_lgbm(X_train, y_train)\n",
        "\n",
        "val_pred = ensemble.predict(X_val)\n",
        "print(\"MAE:\", mean_absolute_error(y_val, val_pred))\n",
        "print(\"SMAPE:\", smape(y_val, val_pred))\n"
      ],
      "metadata": {
        "id": "kT-tr2IxMZsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pred = ensemble.predict(test_embeddings)\n",
        "final_pred = np.maximum(final_pred, 0.0)  # ensure positive\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"sample_id\": test_df[\"sample_id\"],\n",
        "    \"price\": final_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"test_out.csv\", index=False)\n",
        "print(\"Saved test_out.csv\")\n"
      ],
      "metadata": {
        "id": "vspm4q0LMfh5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}